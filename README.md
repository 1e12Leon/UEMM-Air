# UEMM-Air: A Synthetic Multi-modal Dataset for Unmanned Aerial Vehicle Object Detection

The development of multi-modal object detection for Unmanned Aerial Vehicles (UAVs) typically relies on a large amount of pixel-aligned multi-modal image data. However, existing datasets face challenges such as limited modalities, high construction costs, and imprecise annotations. To this end, we propose a synthetic multi-modal UAV-based object detection dataset, UEMM-Air. Specially, we simulate various UAV flight scenarios and object types using the Unreal Engine (UE). Then we design the UAV's flight logic to automatically collect data from different scenarios, perspectives, and altitudes. Finally, we propose a novel heuristic automatic annotation algorithm to generate accurate object detection labels. In total, our UEMM-Air consists of 20k pairs of images with 5 modalities and precise annotations. 
Moreover, we conduct numerous experiments and establish new benchmark results on our dataset. We found that models pre-trained on UEMM-Air exhibit better performance on downstream tasks compared to other similar datasets. 

![å›¾ç‰‡1](https://github.com/1e12Leon/UEMM-Air/assets/44053847/56f0e7b2-a757-4386-a47c-bceada76b79c)

## Download the Dataset ðŸ“‚

### The Whole UEMM-Air
*  [BaiduYun](https://pan.baidu.com/s/1tny1Y8XS0K9bvBdWcToe8g?pwd=y6i7) 

### RGB
Coming Soon!

### Surface Normal
Coming Soon!

### Segmentation
Coming Soon!

### Depth
Coming Soon!

### Annotations
Coming Soon!

## CitationðŸŽˆ

```bibtex
@misc{liu2024uemmair,
      title={UEMM-Air: A Synthetic Multi-modal Dataset for Unmanned Aerial Vehicle Object Detection}, 
      author={Fan Liu and Liang Yao and Shengxiang Xu and Chuanyi Zhang and Xinlei Zhang and Ting Wu},
      year={2024},
      eprint={2406.06230},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```
